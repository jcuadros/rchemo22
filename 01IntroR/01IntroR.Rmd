---
pagetitle: "R for Chemistry Data Analysis and Chemometrics. Introduction to R"
output:
  revealjs::revealjs_presentation:
    theme: simple
    slide_level: 2
    highlight: pygments
    center: false
    self_contained: true
    css: "../css/styles.css"
    reveal_options:
      slideNumber: true
      previewLinks: false
      transition: 0
      background_transition: 0
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, dev="svg")
```

## 

<img src="../images/IQSlogo.png" style="border-style:none;box-shadow:none;
position:absolute;margin:0;top:20px;left:20px;max-width:200px;height:auto;" />

<div style="font-size:1.5em;font-weight:700;margin-top:200px;">R for Chemistry Data Analysis and Chemometrics</div>
<div style="font-size:1.4em;font-weight:500;color:#333333;">Introduction to R</div>
<div style="font-size:1.2em;margin-top:40px;color:#333333;">Jordi Cuadros, Vanessa Serrano</div>
<div style="margin-top:80px;color:#333333;">January 2022</div>


# R Basics

## R

R is a software environment for statistical computing and graphics. It is open source, free to use, and has a really large and active community. There are more than 10000 packages with additional functions, tools and data sets. It is among the most used tools in data analysis and data science.

<https://www.r-project.org/about.html><br/>
<https://www.rdocumentation.org/><br/>
<https://stackoverflow.com/questions/tagged/r>


## Installing R & RStudio

-   **R**

    R is available for multiple platforms at <https://cran.r-project.org/>.

-   **RStudio**

    RStudio is an Integrated Development Environment (IDE) for R.

    It can be downloaded and installed from <https://www.rstudio.com/>. RStudio Desktop (Open Source License) version is available at no cost.

## RStudio Interface

![](../images/RStudio.png)

## Calculations in R

Calculations can be done in the RStudio console. Enter the expression, press `Intro` to execute.

```{r, echo = TRUE}
2 + 3 
8 ^ 10
log(100)    # Natural logarithm (this is a comment)
```


## Using Scripts

A script is a text file that contains a set of R instructions. This allows saving and restoring workflows as well as running them in unmanned mode. In R, they are commonly saved with the `.R` extension.

**RStudio** is a highly recommended editor for R. It allows creating, executing and debugging these scripts. Scripts are edited on the top-left pane.

Current selection (or instruction if nothing is selected) is executed by pressing `Ctrl + Return` or hitting the `Run` command button on the interface.

## Help

-   To look up a function

```{r, echo = TRUE, eval = FALSE}
? "mean"
help("mean")
```

-   To search for a text in the help files

```{r, echo = TRUE, eval = FALSE}
?? "anova"
help.search("anova")
```

In **RStudio**, `F1` can be used to search for the selected text in help. This works only in the pane for editing scripts.

# Basic Data Types

## Basic Data Types

Basic or atomic data types are

-   `numeric`: 15-digit decimal number
-   `integer`: 32-bit integer (to \~2·10^9^)
-   `character`: character string of undefined length
-   `logical`: `TRUE` or `FALSE`

Although less common in science, there are also `complex` and `raw` data types.

## Basic Data Types -- `numeric`

To store numerical quantities which are continuous in nature.

```{r, echo = TRUE}
a <- 2
a
class(a)
b <- 13.6788956789
b
print(b, digits = 10)
```

------------------------------------------------------------------------

### Common operators for `numeric` data

|                     |                   |
|:--------------------|:-----------------:|
| Addition            |        `+`        |
| Subtraction         |        `-`        |
| Product             |        `*`        |
| Division            |        `/`        |
| Power               |    `^` or `**`     |
| Modulus (remainder) |       `%%`        |
| Integer division    |       `%/%`       |
| Comparisons         | `== > < >= <= !=` |

------------------------------------------------------------------------

```{r, echo = TRUE}
a+b
a-b
a*b
a^b
a/b

```

## Basic Data Types -- `integer`

To store integer numbers, such as counts and indices.

```{r, echo = TRUE}
n <- as.integer(340000)
class(n)
n <- 2L
class(n)
```

## Basic Data Types -- `character`

To store text (character strings) of any length.

Character-string literals are quoted (using double or single quotes).

```{r, echo = TRUE}
a <- "aaa"
b <- "bbb"

paste(a, b, "hola", sep = ", ") 
```

------------------------------------------------------------------------

### Common operators for `character` data

|             |                   |
|:------------|:-----------------:|
| Comparisons | `== > < >= <= !=` |

## Basic Data Types -- `logical`

To store values that are either `r T` or `r F`. This is the result of a comparison.

```{r, echo = TRUE}
3 == 2
b <- 3 != 2 
b
```

------------------------------------------------------------------------

### Common operators for `logical` data

|                      |         |
|:---------------------|:-------:|
| Logical intersection |   `&`   |
| Logical union        |   `|`   |
| Logical negation     |   `!`   |
| Comparisons          | `== !=` |

For multiple logical values, `any` and `all` can be used for logical union and intersection respectively.

------------------------------------------------------------------------

For example...

```{r, echo = TRUE}
a <- TRUE
b <- F
a & b # Operator AND
a | b # Operator OR
!b  # Operator NOT
all(a, !b, T)
any(a, b, F)
```

## Conversion between Basic Data Types

Data can be converted to a different data type by using a type conversion function. These are named `as.` followed by the destination data type in R.

```{r, echo = TRUE}
as.character(2)
as.numeric(TRUE)
```

------------------------------------------------------------------------

Be aware that not all conversions are possible.

```{r, echo = TRUE}
as.numeric("two")
as.logical("2+2==4")
```

To check for a specific data type, functions `is.` followed by the data type are also available.

## Constants

Some constants are readily available in R.

```{r, echo = TRUE}
pi
LETTERS  # This is vector. We'll come back to that.
```

```{r, echo = TRUE, eval = FALSE}
Inf
NaN
NA
NULL
```

------------------------------------------------------------------------

Functions to check if a value matches one of these constants are also available.

```{r, echo = TRUE}
is.na(3/0)
is.null(NULL)
is.infinite(-3e999)
```

# Data Structures

## Data Structures

-   Vector
-   Factor
-   Data frame
-   Other data structures
    -   Ordered Factor
    -   List
    -   Matrix
-   Objects: S3, S4, R6... Check <https://adv-r.hadley.nz/oo.html> for more information.


## Data Structures -- vector

```{r, echo = TRUE}
a <- c(2, 3, 4)
str(a)
a[2]
```

------------------------------------------------------------------------

Most operations are applied to vectors element-wise.

```{r, echo = TRUE}
a
a + a 
a > 2.5
```

------------------------------------------------------------------------

Be cautious with data recycling...

```{r, echo = TRUE}
a <- c(2, 3, 4)
b <- c(10, 20)
a * b
```

------------------------------------------------------------------------

Most R functions take vectors and return vectors.

```{r, echo = TRUE}
a <- c(2, 3, 4)
abs(sin(a))
exp(a)
```

------------------------------------------------------------------------

Other returns aggregated values.

```{r, echo = TRUE}
length(a)
sum(a)
mean(a)
```

Also `sd`, `max`, `min`...

------------------------------------------------------------------------

The presence of an element in vector can be checked with `%in%`.

```{r, echo = TRUE}
a <- c(2, 3, 4)
3 %in% a
c(2,5,3,4) %in% a
```

------------------------------------------------------------------------

### Sequence vectors

Sequence vectors are created with `:` or `seq`.

```{r, echo = TRUE}
1:10
seq(1, 10, by = 2)
seq(1, 3, length.out = 5) 
```

------------------------------------------------------------------------

### Sorting vectors

Vectors are ordered with `sort` or `order`.

```{r, echo = TRUE}
a <- c(8, 2, 5, 3)
sort(a)
a[order(a)]
a[order(a,decreasing = T)]
```

------------------------------------------------------------------------

### Selecting elements

```{r, echo = TRUE}
a <- 10:40
a[3]
a[4:6]
a[7] <- 0
b <- a[a!=0]
b
length(b)
```


## YOUR TURN {data-background=#eeffcc}

1.    Create a numerical vector that includes all multiples of seven up to 1000.

2.    Exclude the numbers that have a last digit equal to 3. Here is a hint (`%%` is the modulus/remainder operation): try `1004 %% 10`

3.    How many numbers are left in the vector?

4.    How many of these numbers have a 5 in their representation?


## Data Structures -- factor

A factor is an indexed character vector. It is usually created from a character vector.

```{r, echo = TRUE}
a <- c("hola", "adeu","hola", "adeu", "adeu", "bye")
b <- as.factor(a)
as.character(b)   # returns a character vector
as.numeric(b)     # returns an integer vector of level indices
str(b)
```

------------------------------------------------------------------------

The `factor` function allows manually coding or re-coding the factor.

```{r, echo = TRUE}
a <- factor(c(3, 1, 3, 1, 1, 2), labels = c("adeu", "bye", "hola"))
a
levels(a)
```

## Data Structures -- data frame

A data frame is a rectangular structure of data, organized such as each column is a vector. Different columns may be of different data types.

```{r, echo = TRUE}
dfA <- data.frame(int = 1:10,
                  let = sample(letters, 10, replace = TRUE), 
                  ran = rnorm(10))
dfA
```

------------------------------------------------------------------------

```{r, echo = TRUE}
dim(dfA) # Dimensions
nrow(dfA) # Row count
ncol(dfA) # Column count
```

------------------------------------------------------------------------

```{r, echo = TRUE}
str(dfA)
head(dfA, 3) # First rows, 6 by default
tail(dfA, 2) # Last rows
```

------------------------------------------------------------------------

To access the data in a data frame, we use indices for row and column (starting at 1). Variables can also be selected by column name by using `$`.

```{r, echo = TRUE}
dfA[2,3]
dfA[,1]
dfA$let
```

Additional options exist to select rows and columns. We'll go into that later on.


## YOUR TURN {data-background=#eeffcc}

1.    Create a data frame that includes five different properties for eight *n*-alkanes. Data can be obtained from <https://chem.libretexts.org/Bookshelves/Organic_Chemistry/Book%3A_Basic_Principles_of_Organic_Chemistry_(Roberts_and_Caserio)/04%3A_Alkanes/4.02%3A_Physical_Properties_of_Alkanes_and_The_Concept_of_Homology> or <https://doi.org/10.1007/s40747-020-00262-0> for example. Include, at least, IUPAC name, formula, number of carbons and boiling point. 


## Other Data Structures -- list

Lists are one-dimensional structures that can store data of different types.

```{r, echo = TRUE}
a <- list(2, "2", FALSE)
b <- list(3, "hola", c(2, 3, 4))
```

::: {style="column-count:2;"}
```{r, echo = TRUE}
a
```

 

<p style="display:block;break-after:column;">

</p>

```{r, echo = TRUE}
b
```
:::

------------------------------------------------------------------------

::: {style="column-count:2;"}
```{r, echo = TRUE}
length(a)
a[[3]]
b[[3]][1]
```

 

<p style="display:block;break-after:column;">

</p>

```{r, echo = TRUE}
str(b)
```
:::

## Other Data Structures -- ordered factor

```{r, echo = TRUE}
grades <- c("Pass", "Fail", "Good", "Fail",
           "Good", "Excellent", "Pass")
grades <- factor(grades,
        levels = c("Fail", "Pass",
                   "Good", "Excellent"),
        ordered = TRUE)
str(grades)
levels(grades)
```

## Other Data Structures -- matrix

A matrix is a rectangular data structure where all data share the same data type.

```{r, echo = TRUE}
a <- matrix(c(2, 4, -1, 5), ncol = 2)
a
a[2,2]
```

------------------------------------------------------------------------

::: {style="column-count:2;"}

```{r, echo = TRUE}
a * a # Element-wise product
a %*% a # Matrix product
t(a) # Transposition
det(a) # Determinant
```

 

<p style="display:block;break-after:column;">

</p>

```{r, echo = TRUE}
solve(a) # Inverse
a %*% solve(a)
```
:::


# Basic Graphics in R

## ¿Why Using Graphics?

Main uses of graphics and visualization in data analysis are

-   data exploration and interpretation,
-   non-evident pattern discovery, and
-   communication of analysis results.

## Graphics in R

R includes many paradigms for graphics development. These include

-   R `base` plots,
-   Grammar Of Graphics (*GoG*) based representations, with the `ggplot2` package,
-   Lattice charts, using the `lattice` package,
-   A formula-based grammar of graphics, `ggformula`,
-   `ggvis`, an interactive grammar of graphics framework, among many others.

We will here discuss the simplest charts, those from `base` R.


## Graphics in `base` R

Graphics in `base` R are usually constructed from vectors by using specific functions depending on the desired chart.

To exemplify some of these functions we will use the `airquality` data set, one of many data sets included in `base`R.

Access help for details on the data set..

```{r, echo = TRUE, eval = FALSE}
help("airquality")
```

------------------------------------------------------------------------

```{r, echo = TRUE}
str(airquality)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
head(airquality, 10)
```

------------------------------------------------------------------------

We will show how to make

-   scatterplots,
-   histograms,
-   bar plots, and
-   boxplots


## Graphics in `base` R -- scatterplot

```{r, echo = TRUE, eval = FALSE}
plot(airquality$Solar.R,airquality$Ozone)
```

------------------------------------------------------------------------

```{r, echo = FALSE, eval = TRUE}
plot(airquality$Solar.R,airquality$Ozone)
```

------------------------------------------------------------------------

## Graphics in `base` R -- histogram

```{r, echo = TRUE, eval = FALSE}
hist(airquality$Ozone)
```

With a density curve...

```{r, echo = TRUE, eval = FALSE}
hist(airquality$Ozone, breaks = 23, freq = FALSE)
lines(density(airquality$Ozone, na.rm=TRUE))
```

------------------------------------------------------------------------

```{r, echo = FALSE, eval = TRUE}
hist(airquality$Ozone)
```

------------------------------------------------------------------------

```{r, echo = FALSE, eval = TRUE}
hist(airquality$Ozone, breaks = 23, freq = FALSE)
lines(density(airquality$Ozone, na.rm=TRUE))
```

------------------------------------------------------------------------

## Graphics in `base` R -- bar plot

```{r, echo = TRUE, eval = FALSE}
barplot(table(cut(airquality$Wind, breaks=seq(0,22,by=2))))
```

------------------------------------------------------------------------

```{r, echo = FALSE, eval = TRUE}
barplot(table(cut(airquality$Wind, breaks=seq(0,22,by=2))))
```

## Graphics in `base` R -- boxplot

```{r, echo = TRUE, eval = FALSE}
boxplot(airquality$Ozone)
points(mean(airquality$Ozone, na.rm=TRUE),pch="+")
```

------------------------------------------------------------------------

```{r, echo = FALSE, eval = TRUE}
boxplot(airquality$Ozone)
points(mean(airquality$Ozone, na.rm=TRUE),pch="+")
```


# Basic Stats with R

## Statistics Goals

**Statistics** is the mathematics sub-discipline which covers the collection, analysis and interpretation of data. It has two main goals:

1.  To describe a set of data (**descriptive statistics**), y
2.  To extract conclusions about the population from the available data (**inferential statisitcs**)

In this statistics review, we will again use the `airquality` data set. Details on the data set are avalable at...

```{r, echo = TRUE, eval = FALSE}
help("airquality")
```

------------------------------------------------------------------------

```{r, echo = TRUE}
str(airquality)
```


## Descriptive statistics for one variable

Often, we need to start by exploring and describing each variable data. Let's start here. 

Common aspects to consider when analyzing a single variable are 

-   distribution: frequencies and quantiles,
-   central tendency (also referred as location o position),
-   spread, and
-   analysis of outliers.


## Descriptive statistics for one variable -- distribution

### Summary 
```{r, echo = TRUE}
summary(airquality)
```

------------------------------------------------------------------------

### Sample size or number of data points
```{r, echo = TRUE}
length(airquality$Ozone)
n <- sum(!is.na(airquality$Ozone))
n
```

------------------------------------------------------------------------

### Absolute and relative frequencies

For a quantitative variable (`numeric`)...

```{r, echo = TRUE}
frec_abs <- table(cut(airquality$Solar.R,
      breaks=c(0,50,100,150,200,
               250,300,350)))
frec_abs

frec_rel <- frec_abs / sum(frec_abs)
frec_rel
```

------------------------------------------------------------------------

For a qualitative variable (usually `factor`)...

```{r, echo = TRUE}
frec_abs <- table(as.factor(airquality$Month))
frec_abs

frec_rel <- frec_abs / sum(frec_abs)
frec_rel
```

------------------------------------------------------------------------

### Quantiles

```{r, echo = TRUE}
quantile(airquality$Wind,.1)
quantile(airquality$Wind,0:5*.2)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
# Excel PERCENTILE and R default are type 7
c(min = min(airquality$Wind), quantile(airquality$Wind,0:5*.2),
  max = max(airquality$Wind))    
# Excel PERCENTILE.EXC, SPSS and Minitab default are type 6
c(min = min(airquality$Wind), quantile(airquality$Wind,0:5*.2, type=6),
  max = max(airquality$Wind))

```


## Descriptive statistics for one variable -- central tendency

```{r, echo = TRUE}
mean(airquality$Ozone)
mean(airquality$Ozone, na.rm = TRUE)
median(airquality$Ozone, na.rm = TRUE)
```

## Descriptive statistics for one variable -- spread

```{r, echo = TRUE}
var(airquality$Ozone, na.rm = TRUE) # denominator is n-1
sd(airquality$Ozone, na.rm = TRUE)
range(airquality$Ozone, na.rm = TRUE)
diff(range(airquality$Ozone, na.rm = TRUE))
```

------------------------------------------------------------------------

```{r, echo = TRUE}
IQR(airquality$Ozone, na.rm = TRUE)
mad(airquality$Ozone, na.rm = TRUE) # mean absolute deviation
```

## Descriptive statistics for one variable -- outliers

There are different methods to analyze outliers in R. A nice description can be found at <https://statsandr.com/blog/outliers-detection-in-r/>

```{r, echo = TRUE}
# Hampel filter  
lmin <- median(airquality$Wind,.25) - 3 * mad(airquality$Wind)
lmax <- median(airquality$Wind,.75) + 3 * mad(airquality$Wind) 
c(as.numeric(lmin),as.numeric(lmax))
airquality$Wind[airquality$Wind > lmax | airquality$Wind < lmin]
```

------------------------------------------------------------------------

```{r, echo = TRUE}
# IQR method
lmin <- quantile(airquality$Wind,.25) - 1.5 * IQR(airquality$Wind)
lmax <- quantile(airquality$Wind,.75) + 1.5 * IQR(airquality$Wind) 
c(as.numeric(lmin),as.numeric(lmax))
airquality$Wind[airquality$Wind > lmax | airquality$Wind < lmin]
boxplot.stats(airquality$Wind)$out
```


## Descriptive statistics for one variable -- plots

Plots are also useful to describe a data set.

-   For quantitative variables: boxplot and histogram

```{r, echo = TRUE, eval = FALSE}
boxplot(airquality$Wind)
points(mean(airquality$Wind),pch=3)

hist(airquality$Wind)
```

-   For qualitative variables: bar plot

```{r, echo = TRUE, eval = FALSE}
barplot(table(airquality$Month))
```

------------------------------------------------------------------------

```{r, echo = FALSE}
boxplot(airquality$Wind)
points(mean(airquality$Wind),pch=3)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
hist(airquality$Wind)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
barplot(table(airquality$Month))
```


## Descriptive statistics for two variables

To study and describe the relation between two variables, common techniques include

-   contingency tables,
-   correlation coefficients, and
-   scatterplots.


## Descriptive statistics for two variables -- cotingency table

The contingency table is a two-way frequency table.

```{r, echo = TRUE}
table(cut(airquality$Wind,breaks = seq(1,21,by=5)),
      cut(airquality$Temp,breaks = seq(50,100,by=10)))
```

## Descriptive statistics for two variables -- correlation coeffcient

### Pearson product-moment correlation coefficent

```{r, echo = TRUE}
cor(airquality$Temp,airquality$Wind)
```

### Spearman correlation coefficent

```{r, echo = TRUE}
cor(airquality$Temp,airquality$Wind,method = "spearman")
```

## Descriptive statistics for two variables -- scatterplot

```{r, echo = TRUE, eval = FALSE}
plot(airquality$Temp,airquality$Wind)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
plot(airquality$Temp,airquality$Wind)
```


## Probability Distributions

A probability distribution of a random number corresponds to the abstraction of the density distribution of a set of infinite number of data with the same origin.

A large number of experimental distributions have related theoretical models. The most common theoretical distributions are the normal distribution (for continuous variables), the uniform distribution (for continuous or discrete variables), and the binomial distribution (for the number of successes of a discrete event with a defined probability).

------------------------------------------------------------------------

In **R**, all theoretical distributions share the same system of functions

-   `r<dist>`: to generate random numbers according to the distribution
-   `d<dist>`: to calculate the density for a value of the variable
-   `q<dist>`: to obtain the value of the variable (quantile) for an accumulated probability
-   `p<dist>`: to obtain the accumulated probability for a value of the variable

------------------------------------------------------------------------

For example, for the normal distribution...

```{r, echo = TRUE}
rnorm(10)
dnorm(0)
qnorm(.95)
pnorm(1.64)
```

## Probability Distributions -- normal

```{r, echo = TRUE, eval = FALSE}
df <- data.frame(x = rnorm(1000, mean = 3, sd = 1))
dfT <-data.frame(x = seq(0,6,length.out=101),
      y = dnorm(seq(0,6,length.out=101),mean=3,sd=1))
hist(df$x,breaks=2*ceiling(max(df$x)-min(df$x)))
lines(dfT$x,dfT$y*1000*0.5)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
df <- data.frame(x = rnorm(1000, mean = 3, sd = 1))
dfT <-data.frame(x = seq(0,6,length.out=101),
      y = dnorm(seq(0,6,length.out=101),mean=3,sd=1))
hist(df$x,breaks=2*ceiling(max(df$x)-min(df$x)))
lines(dfT$x,dfT$y*1000*0.5)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
pnorm(5,mean = 3,sd = 1)
qnorm(.98,mean = 3,sd = 1)
pnorm(1:5,mean = 0,sd = 1)
qnorm(c(0.95,0.975,.99,.995,.999),mean = 0,sd = 1)

```

## Probability Distributions -- uniforme

```{r, echo = TRUE, eval = FALSE}
df <- data.frame(x = runif(1000, min = 10, max = 20))
dfT <-data.frame(x = seq(10,20,length.out=101),
      y = dunif(seq(10,20,length.out=101), min=10, max=20))
hist(df$x,breaks=2*ceiling(max(df$x)-min(df$x)))
lines(dfT$x,dfT$y*1000*0.5)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
df <- data.frame(x = runif(1000, min = 10, max = 20))
dfT <-data.frame(x = seq(10,20,length.out=101),
      y = dunif(seq(10,20,length.out=101), min=10, max=20))
hist(df$x,breaks=2*ceiling(max(df$x)-min(df$x)))
lines(dfT$x,dfT$y*1000*0.5)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
punif(12, min=10, max=20)
qunif(.90, min=10, max=20)
```

## Probability Distributions -- binomial

```{r, echo = TRUE, eval = FALSE}
df <- data.frame(x = rbinom(100,5,prob=0.5))
barplot(table(df$x))
```

------------------------------------------------------------------------

```{r, echo = FALSE}
df <- data.frame(x = rbinom(100,5,prob=0.5))
barplot(table(df$x))
```

------------------------------------------------------------------------

```{r, echo = TRUE}
pbinom(2,5,prob=0.5)
qbinom(.5,5,.5)
```

## Probability Distributions -- other

**R** includes many other distributions that can be looked up in the help files.

```{r, echo = TRUE, eval = FALSE}
? "Distributions"
```


## Inference

In statistics, inference is the determination of information about the population --the entire set of existing values-- from a representative sample and some data model hypothesis.

In case the sample is not representative, any information inferred from it will be biased, potentially displaced from its actual value.

------------------------------------------------------------------------

Inference results are commonly shown in either of the following two formats:

-   the value of population parameters, usually associated to an error or confidence interval,
-   the probability (*p*) that the observed data, or any data more extreme than the observed, could be produced from an hypothesized data model, the null hypotesis.

------------------------------------------------------------------------

We will be reviewing here, while we show how to apply them in R, the most common procedures

-   to discuss a fit to a  **distribution**,
-   to study the population **spread**, and
-   to estimate or to compare **central tendency** values.


## Inference -- distribution

To test the fit to a theoretical distribution, the most common test are the **chi-squared goodness-of-fit test** (`chisq.test`) and the **test of Kolmogorov-Smirnov** (`ks.test`). In both cases, the arguments are the observed absolute frequencies and the probabilities expected according to the theoretical distribution.

*NOTE*: The `ks.test` is not appropriate when the distribution to test is fitted to the sample data --i.e. for the Lilliefors test for normality.

------------------------------------------------------------------------

### Example

A 10-face dice is thrown a hundred times. The table below shows the results for the experiment.

|  1  |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | 10  |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|  9  |  6  |  7  | 15  | 11  | 11  |  9  | 13  |  9  | 10  |

If the dice was normal, each face should have the same probality of appearing. Is it the case?

------------------------------------------------------------------------

```{r, echo = TRUE}
obs <- c(9, 6, 7, 15, 11, 11, 9, 13, 9, 10)  
exp <- rep(.1, 10)
 
chisq.test(x = obs, p = exp)
```

------------------------------------------------------------------------

Although with less objectivity, graphical methods can also be used to compare distributions. This is usually done through a quantile-quantile plot --in R,  `qqplot`.

If both data sets belong to the same distribution, their quantiles will appear aligned on the diagonal of the plot (especially on the central region of the chart).


```{r, echo = TRUE, eval = FALSE}
exp <- rep(1:10, obs)
teo <- rep(1:10, 10)
qqplot(x = exp, y = quantile(teo, (1:length(exp))/length(exp)))
qqline(y = exp, distribution = function(x)  quantile(teo,x),
       probs= c(1/length(exp),1))
```

------------------------------------------------------------------------

```{r, echo = FALSE}
exp <- rep(1:10, obs)
teo <- rep(1:10, 10)
```

```{r, echo = FALSE}
qqplot(x = exp, y = quantile(teo, (1:length(exp))/length(exp)))
qqline(y = exp, distribution = function(x)  quantile(teo,x),
       probs= c(1/length(exp),1))
```

------------------------------------------------------------------------

To check if a data set might be a random sample of a population following a normal distribution, there are specific tests. Among the most common ones, there are the Shapiro-Wilk normality test  and the Anderson-Darling normality test. Only the former is available in R *base*.

------------------------------------------------------------------------

```{r, echo = TRUE}
x1 <- rnorm(20, mean = 4, sd = 5)
x2 <- rbeta(20, shape1 = 5, shape2 = .5, ncp = 4)

shapiro.test(x1)
shapiro.test(x2)

```

------------------------------------------------------------------------

Graphically, the quantile-quantile plot can also be used. In R, the `qqnorm` function provide a direct comparison with the normal distribution.

```{r, echo = TRUE, eval = FALSE}
qqnorm(x1)
qqline(x1)

qqnorm(x2)
qqline(x2)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
qqnorm(x1)
qqline(x1)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
qqnorm(x2)
qqline(x2)
```


## Inference -- spread

The most common inferences respect to the spread of a population fall in the following cases:

-   assessing a confidence interval for the variance or the standard deviation,
-   comparing the spread of two populations,
-   comparing the spread of three or more populations --or testing the homocedastacity of different data sets--.

------------------------------------------------------------------------

When sample dats come from a normal distribution, the **confidence interval for the variance** can be calculated from the chi-squared distribution.

```{r, echo = TRUE}
x <- rnorm(50, mean = 0, sd = 2)
df <- length(x) - 1
lower <- var(x) * df / qchisq(1 - 0.05/2, df)
upper <- var(x) * df / qchisq(0.05/2, df)
c(lower = lower, var = var(x), upper = upper)
```

------------------------------------------------------------------------

To calculate the **confidence interval for the standard deviation**, when data come from a normal distribution, we proceed by taking the square root of the limits of the confidence interval for the variance.

```{r, echo = TRUE}
c(lower = sqrt(lower), sd = sd(x), upper = sqrt(upper))
```

------------------------------------------------------------------------

To compare **the spread of two populations**, when data come from normal distributions, we use an F test -- `var.test` in R--.

```{r, echo = TRUE}
x <- rnorm(50, mean = 0, sd = 2)
y <- rnorm(30, mean = 1, sd = 1)
var.test(x, y)
```

------------------------------------------------------------------------

If the data don't come from a normally distributed population, spreads (scales) can be compared with the Ansari-Bradley test.


```{r, echo = TRUE}
x <- rlnorm(50, meanlog = 2, sdlog = 1)
y <- rlnorm(30, meanlog = 2, sdlog = .2)
ansari.test(x, y)
```

------------------------------------------------------------------------

To compare the spread (scales) of more than two normally distributed populations, the Bartlett test --`bartlett.test` in R-- is commonly used.

```{r, echo = TRUE, eval = FALSE}
x1 <- round(rnorm(20, mean = 1, sd = 2),1)
x2 <- round(rnorm(20, mean = 3, sd = 2),1)
x3 <- round(rnorm(20, mean = 5, sd = 2),1)
list(x1,x2,x3)
bartlett.test(list(x1,x2,x3))
```

------------------------------------------------------------------------

```{r, echo = FALSE}
x1 <- round(rnorm(20, mean = 1, sd = 2),1)
x2 <- round(rnorm(20, mean = 3, sd = 2),1)
x3 <- round(rnorm(20, mean = 5, sd = 2),1)
list(x1,x2,x3)
bartlett.test(list(x1,x2,x3))
```

------------------------------------------------------------------------

In case any of the populations is not normally distributed, Fligner-Killeen test --in R, `fligner.test`--, Levene test --`leveneTest` in the R `car` package-- or Brown--Forsythe test --`bf.test` in the R `onewaytests` package-- can be useful.

------------------------------------------------------------------------

Graphically, although with less objectivity, either boxplots or boxplots of the centered data can be used.

```{r, echo = TRUE, eval = FALSE}
x1 <- round(rnorm(20, mean = 1, sd = 2),1)
x2 <- round(rnorm(20, mean = 3, sd = 2),1)
x3 <- round(rnorm(20, mean = 5, sd = 2),1)

xs <- data.frame(
  group = factor(c(rep(1, length(x1)),rep(2, length(x2)),
            rep(3, length(x3)))),
  y = c(x1,x2,x3),
  centered = c(x1 - median(x1),x2 - median(x2),x3 - median(x3)))

boxplot(y~group,data=xs)
boxplot(centered~group,data=xs)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
x1 <- round(rnorm(20, mean = 1, sd = 2),1)
x2 <- round(rnorm(20, mean = 3, sd = 2),1)
x3 <- round(rnorm(20, mean = 5, sd = 2),1)

xs <- data.frame(
  group = factor(c(rep(1, length(x1)),rep(2, length(x2)),
            rep(3, length(x3)))),
  y = c(x1,x2,x3),
  centered = c(x1 - median(x1),x2 - median(x2),x3 - median(x3)))

boxplot(y~group,data=xs)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
boxplot(centered~group,data=xs)
```

## Inference -- location

The main inferences for location --or central tendency-- of a population correspond to

-   establishing a confidence interval for the central tendency of the distribution,
-   comparing the central tendency of a population to predefined value,
-   comparing the central tendency of two populations, and
-   comparing the central tendency of three or more populations.

------------------------------------------------------------------------

To calculate a *confidence interval for the mean* of a normally distributed population, we use the Student (or t) distribution. In R, it can be calculates form the `qt` function, or also as one of the results of the `t.test` function.

```{r, echo = TRUE}
x <- rnorm(10, mean = 2, sd = .5)
x
```

------------------------------------------------------------------------

```{r, echo = TRUE}
t.test(x)
```

------------------------------------------------------------------------

If the population does not follow a normal distribution, a nonparametric **confidence interval for the median** can be calculated by using the `wilcox.test` function.

```{r, echo = TRUE}
x <- rnorm(10, mean = 3, sd = .5) ^ 3
x
wilcox.test(x, conf.int = TRUE)
```

------------------------------------------------------------------------

Both function presented to obtain the confidence intervals, can also **compare the central tendency of a population to a predefined value**. As already said, the t test works for a normally distributed population; the Wilcoxon test does not have this requirement.

```{r, echo = TRUE}
x <- rnorm(10, mean = 2, sd = .5)
x
```

------------------------------------------------------------------------

```{r, echo = TRUE}
t.test(x, mu = 1.5)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
median(x^3)
wilcox.test(x ^ 3, mu = 8)
```

------------------------------------------------------------------------

To **compare the location** of two populations, three prior considerations should be made.

-   Are both data samples independent or data are paired?
-   Are both populations normally distributed?
-   Have both populations the same scale?

------------------------------------------------------------------------

Data are **associated** or **paired** when there are pairs of values --one from each data set-- that share some sources of variation (same person, same object, same date...). In this case

-   if **both populations are normally distributed** or the difference population is normally distributed, a t test on the difference of the data ca be used to compare the location of the populations. In R, one can calculate the difference and then use the `t.test` with a single vector as argument, or directly use the `t.test` with `paired = TRUE`,
-   if **the populations are not normally distributed**, we use the Wilcoxon test --`wilcox.test` on the difference o with the option `paired = TRUE` in R--.

------------------------------------------------------------------------

```{r, echo = TRUE}
x <- rnorm(10, mean = 3, sd = 1)
y <- rnorm(10, mean = 3.5, sd = 1)
list(x = x,y = y)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
t.test(x - y)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
t.test(x, y, paired = TRUE)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
x <- rlnorm(10, meanlog = 3, sdlog = 1)
y <- rlnorm(10, meanlog = 3.5, sdlog = 1)
list(x = x,y = y)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
wilcox.test(x - y)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
wilcox.test(x, y, paired = TRUE)
```

------------------------------------------------------------------------

If **data samples are not associated** then

-   if both **populations are normally distributed**, we use the t test. In R, we run the test with the function `t.test`; the option `var.equal` allows switching between the test assuming equality of population variances and the Welch t-test, which is the default and does not requires this assumption; 
-   if **any of the populations is not normally distributed** we use the Mann- Whitney U test, also called Wilcoxon rank-sum test,  --`wilcox.test` in R--.

------------------------------------------------------------------------

```{r, echo = TRUE}
x <- rnorm(10, mean = 3, sd = 1)
y <- rnorm(14, mean = 3.5, sd = 2)
list(x = x,y = y)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
t.test(x, y, var.equal = FALSE)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
x <- rlnorm(10, meanlog = 3, sdlog = 1)
y <- rlnorm(14, meanlog = 3.5, sdlog = 2)
list(x = x,y = y)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
wilcox.test(x, y)
```

------------------------------------------------------------------------

To **compare locations for three o more populations**, the most used procedures are 

-   if **distributions are normally distributed** and **they have the same scale** --homocedasticity--, analysis of variance (ANOVA) is used --`aov` in R--;
-   if **distributions are normally distributed** but **they don't have the same scale**, Welch ANOVA is to be used --`oneway.test` in R--;
-   if **distributions not are normally distributed** but distributions have similar shapes, we use the Kruskal-Wallis test --in R, `krukal.test`--. More details can be found at <https://rcompanion.org/handbook/F_08.html>.

------------------------------------------------------------------------

```{r, echo = TRUE}
x <- c(rnorm(10, mean = 3, sd = 1),
       rnorm(8, mean = 3.2, sd = 1),
       rnorm(10, mean = 4, sd = 1))
g <- factor(c(rep(1,10), rep(2,8), rep(3,10)))
test <- aov(x ~ g)
summary(test)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
x <- c(rnorm(10, mean = 3, sd = 1),
       rnorm(8, mean = 3.2, sd = 4),
       rnorm(10, mean = 4, sd = 2))
g <- factor(c(rep(1,10), rep(2,8), rep(3,10)))
oneway.test(x ~ g)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
x <- c(runif(10, min = 2, max = 4),
       runif(8, min = 1.5, max = 3.5),
       runif(10, min = 3, max = 5))
g <- factor(c(rep(1,10), rep(2,8), rep(3,10)))
kruskal.test(x ~ g)
```

------------------------------------------------------------------------

Either the ANOVA or the Kruskal-Wallis test only whether there is a difference among the populations or not, but they can not identify what populations (groups) differ in location.

To test which pairs of populations have different locations, we use *post-hoc* tests.

-   In the ANOVA or Welch ANOVA case, we can use the Tukey's HSD test --`TukeyHSD` in R,
-   For the Kruskal-Wallis test, Dunn's test is a commonly used option --`dunn.test` in  the `dunn.test` R package--

------------------------------------------------------------------------

Graphically, although with less objectivity, a boxplot can be used to compare location of different data sets.

```{r, echo = TRUE, eval = FALSE}
x <- c(rnorm(10, mean = 3, sd = 1),
       rnorm(8, mean = 3.2, sd = 1),
       rnorm(10, mean = 4, sd = 1))
g <- factor(c(rep(1,10), rep(2,8), rep(3,10)))

xs <- data.frame(y = x, group = g)
  
boxplot(y~group, data=xs)

```

------------------------------------------------------------------------

```{r, echo = FALSE}
x <- c(rnorm(10, mean = 3, sd = 1),
       rnorm(8, mean = 3.2, sd = 1),
       rnorm(10, mean = 4, sd = 1))
g <- factor(c(rep(1,10), rep(2,8), rep(3,10)))

xs <- data.frame(y = x, group = g)
  
boxplot(y~group, data=xs)
```


## Model fitting

A model is commonly expressed in R with a `formula` object.

In this notation, relation among variables is indicated through a three-term expression, with the dependent variable on the left, a tilde operator (`~`) and a combination of independent variables on the right side

```{r, echo = TRUE}
form1 <- y ~ x              # recta
class(form1)
```

```{r, echo = TRUE, eval = FALSE}
form1 <- y ~ log(x)         # logaritmo
form1 <- y ~ poly(x,4)      # polinomio de grado 4
form1 <- y ~ x + 0          # recta que pasa por el origen
form1 <- y ~ I(x^.5)        # raíz cuadrada
```


## Model fitting -- linear regression

Ordinary least square (OLS) fit can be produced in R, by using the `lm` function. They can also be used for factors; in this case, dummy variables are produced for the levels of the factors (all but the first one). 

```{r, echo = TRUE, eval = FALSE}
fit1 <- lm(Ozone ~ Solar.R, data=airquality)
summary(fit1)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
fit1 <- lm(Ozone ~ Solar.R, data=airquality)
summary(fit1)
```

------------------------------------------------------------------------

```{r, echo = TRUE, eval = FALSE}
fit2 <- lm(Ozone ~ Solar.R + Temp, data=airquality)
summary(fit2)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
fit2 <- lm(Ozone ~ Solar.R + Temp, data=airquality)
summary(fit2)
```


------------------------------------------------------------------------

```{r, echo = TRUE, eval = FALSE}
df <- airquality
df$Month <- factor(df$Month)
fit3<- lm(Temp ~ Month, data=df)
summary(fit3)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
df <- airquality
df$Month <- factor(df$Month)
fit3<- lm(Temp ~ Month, data=df)
summary(fit3)
```

------------------------------------------------------------------------

Once fitted, the model can be used to predict the dependent variable with the `predict` function. To search for help, look up `predict.lm`.

```{r, echo = TRUE}
df <- na.omit(data.frame(x=airquality$Solar.R, y=airquality$Ozone,
  predict(fit1, newdata=airquality, interval="prediction")))
head(df)
```

------------------------------------------------------------------------

The model can be represented from the predictions.

```{r, echo = TRUE, eval = FALSE}
df2 <- data.frame(
  Solar.R = seq(min(airquality$Solar.R,na.rm=TRUE),
                max(airquality$Solar.R,na.rm=TRUE), length.out = 201))
df2 <- cbind(df2, predict(fit1, 
  newdata = df2, interval="prediction"))

plot(range(df2$Solar.R),range(c(df2$lwr,df2$upr)),type="n")
lines(df2$Solar.R,df2$fit,type="l",lwd=2)
lines(df2$Solar.R,df2$upr,col="grey",lwd=1)
lines(df2$Solar.R,df2$lwr,col="grey",lwd=1)
points(airquality$Solar.R,airquality$Ozone,pch="+")
```

------------------------------------------------------------------------

```{r, echo = FALSE}
df2 <- data.frame(
  Solar.R = seq(min(airquality$Solar.R,na.rm=TRUE),
                max(airquality$Solar.R,na.rm=TRUE), length.out = 201))
df2 <- cbind(df2, predict(fit1, 
  newdata = df2, interval="prediction"))

plot(range(df2$Solar.R),range(c(df2$lwr,df2$upr)),type="n")
lines(df2$Solar.R,df2$fit,type="l",lwd=2)
lines(df2$Solar.R,df2$upr,col="grey",lwd=1)
lines(df2$Solar.R,df2$lwr,col="grey",lwd=1)
points(airquality$Solar.R,airquality$Ozone,pch="+")
```

## Model fitting -- checking

To check the goodness and correctness of the fitted model and the fitting approach (OLS), the residuals should be analyzed. They should be random, normally distributed, homocedastic and high-leverage points should not be present.

These checks can be made from the residuals data and the required statistical tests.

```{r, echo = TRUE, eval = FALSE}
fit1$residuals
```

------------------------------------------------------------------------

```{r, echo = TRUE}
df <- na.omit(airquality[,c(2,1)])
head(cbind(df,fit=fit1$fitted.values, res=fit1$residuals))
```

------------------------------------------------------------------------

```{r, echo = TRUE}
shapiro.test(fit1$residuals)
```

------------------------------------------------------------------------

```{r, echo = TRUE}
fligner.test(fit1$residuals, cut(1:length(fit1$residuals),breaks=3))
fligner.test(fit1$residuals,
             cut(fit1$fitted.values-median(fit1$fitted.values),breaks=3))
```

------------------------------------------------------------------------

Graphically, the same aspects can be informed from the plots of the model.

```{r, echo = TRUE, eval = FALSE}
plot(fit1, which=1:6)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
plot(fit1, which=1)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
plot(fit1, which=2)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
plot(fit1, which=3)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
plot(fit1, which=4)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
plot(fit1, which=5)
```

------------------------------------------------------------------------

```{r, echo = FALSE}
plot(fit1, which=6)
```

------------------------------------------------------------------------

Parallel approaches are followed when fitting more complex multilinear models  (`lm`), generalized linear models (`glm`), or non-linear models by least-squares (`nls`), among other options.


# Advanced manipulation of data frames (part 1 - `base` functions)

## Tabla de datos o *data frame*

As introduced above, data frames are the most common data structure to store data sets.

Often preparing the data in specific formats is a requirement for producing data visualizations or running statistical procedures. We will dedicate this block to discuss some common operations in data wrangling. Additional operations will be discussed later on. 

------------------------------------------------------------------------

Common operations on data frame are

-   renaming columns or rows,
-   adding columns or rows,
-   segmenting (selecting columns or rows),
-   removing columns or rows,
-   creating a date frame from combining vectors, 
-   joining data frames,
-   reshaping data tables, and
-   summarizing or aggregating the data.

We will discuss the first six operations here, as these are often done with `base` R functions.

The last two operations will be explained when introducing the `dplyr` R package.

------------------------------------------------------------------------

Let's start synthetic data frame...

```{r, echo = TRUE}
df <- data.frame(number=1:5, letters[1:5], c(rep("a", 3), rep("b", 2)))
df
```


## Renaming columns or rows

```{r, echo = TRUE}
colnames(df) <- c("var1", "var2", "var3") 
rownames(df) <- paste("subject00", 1:5, sep = "")
df
```


## Adding columns or rows

```{r, echo = TRUE}
df2 <- cbind(df, rnorm(5)) # adding a vector to the data frame
df2$var5 <- 5:1 # assigning values to a new named column
df2
```

------------------------------------------------------------------------

```{r, echo = TRUE}
df2 <- rbind(df, list(6, "e", "b"))
df2
```


## Segmenting

There are three basic ways to segment a data frame by selecting rows and columns 

-   by numerical **indices** or subscripts,
-   using column and row **names**, and
-   through **logical vectors**.


## Segmenting -- indices

```{r, echo = TRUE}
df[1:3,]
df[,c(1,3)]
```

------------------------------------------------------------------------

Using negative indices removes rows or columns

```{r, echo = TRUE}
df[-(3:4),-2]
```


## Segmenting -- names

```{r, echo = TRUE}
df[,"var2"]
df$var3
df[,c("var2","var3")]
```


## Segmenting -- logical vectors

```{r, echo = TRUE}
df[c(T,T,F,T,F), c(T,F,T)]
df[df[,1] == 3 | df[,3] == "b",]
```


## Removing columns or rows

The most common way of removing columns or rows is segmenting the data frame. However a column can also be removed by assign it to `NULL`.

```{r, echo = TRUE}
df <- data.frame(1:5, letters[1:5], c(rep("a", 3), rep("b", 2)))
colnames(df) <- c("var1", "var2", "var3") 
rownames(df) <- paste("subject00", 1:5, sep = "")
df <- df[-2,]
df$var2 <- NULL
```

------------------------------------------------------------------------

```{r, echo = TRUE}
df
```

------------------------------------------------------------------------

Rows with `NA` values can be removed with the `na.omit` function.

```{r, echo = TRUE}
df[2,2] <- NA
df <- na.omit(df)

df

```

------------------------------------------------------------------------

In case we want to remove a variable from the environment, we use the `rm` function.

```{r, echo = TRUE, eval = FALSE}
rm(df)
rm(list=ls())   # Remove all variables from environment

```


## Creating a date frame from combining vectors 

```{r, echo = TRUE}
dfExp <- expand.grid(A=c(-1,1),B=c(-1,1), C=c(0,1,2))
dfExp
```


## Joining data frames

Data frames can be joined on common values for the combining variables by using the `merge` function. By default, they are merged on the variables with same names.

```{r, echo = TRUE}
dfC <- data.frame(C=c(0,1,2),
    condC=c("hexane","cyclohexane","THF"))
dfExp <- merge(dfExp, dfC)
head(dfExp)
```


## YOUR TURN {data-background=#eeffcc}

1.    Describe and analyze the data of an experiment conducted to assess the potency of lime sulphur in orchard sprays. The data is available in the `OrchardSprays` data set.

Run `help("OrchardSprays")` to know more about the experiment and the data set.


